# TheAgentCompany 基准测试失败分析

你的主要目标是分析一批来自 TheAgentCompany 基准测试的代理行为日志，找出任务失败（即为什么会丢分）的根本原因，并提出具体的解决方案。

## 输入数据

你需要的所有信息都位于一个文件夹中：`messages`。

在该文件夹中，你会找到多个 `.txt` 文件。每个文件代表一个独立的任务，其**文件名就是任务名加'-image'**。

我已经对每个文件进行了预处理，在文件最开头包含了所有必要的上下文信息。当你打开任何一个 `[任务名]-image.txt` 文件时，你将按顺序看到以下信息：

1.  **任务描述：** 来自原始 `task.md` 的全部内容。
2.  **评分标准：** 来自原始 `checkpoints.md` 的全部内容。
3.  **评分结果：** 来自 `eval_[任务名]-image.json` 文件的完整 JSON 内容。这提供了所有检查点的详细得分明细，让你能准确地看到代理在哪些地方丢分了。
4.  **代理日志：** 在这些头部信息之后，是原始的代理行为日志，包含了代理内部的 "Message"（消息）和它从 LLM（大语言模型）获取的 "Content"（回复内容）。

## 你的任务

你必须逐一处理该文件夹中的每个 `.txt` 文件。对于每个任务，你必须：

1.  **分析失败点：** 阅读任务描述、评分标准和评分结果（`eval.json`），以理解任务目标，并准确定位代理失败的地方。
2.  **识别根本原因：** 将 `eval.json` 中的丢分点与 "代理日志" 中的具体行为相关联，以确定 "问题原因"。
3.  **提出解决方案：** 基于你分析的原因，提出一个 "解决方案"。

## 约束与指南

* **不确定性：** 如果你无法确定一个明确的根本原因，你可以提供一个合理的猜测，但你**必须**在你的 "问题原因" 分析后面追加 `(存疑)` 标记。
* **评分逻辑参考：** 如果你不确定为什么会丢分（即 `eval.json` 中的结果），或想了解具体的评分逻辑，你可以查阅位于 `tasks/[任务名]/evaluator.py` 文件中的代码。
* **解决方案类别：** 当你提出 "解决方案" 时，你**必须**从以下一个或多个框架中选择并进行分类：
    * **提示/指南 (Prompting/Guidelines)：** 修改代理的系统提示、特定任务的模板或操作指南。
    * **记忆 (Memory)：** 改善短期（任务内）或长期（跨任务）记忆。（例如：在任务内部记住过去的失败经验，从其他任务共享成功的策略）。
    * **编排 (Orchestration)：** 修改工具或代理的执行流程。（例如：自动化某个序列、创建一个新的编排流程，或为复杂的修复重用一个成功的规划）。

## 输出格式

你的最终输出必须是一个单一的 Markdown 表格。你将分析每一个任务文件，并在完成分析后，向此表格增量添加一个新行。

表格必须严格包含以下四列：

| 序号 | 任务名称 | 问题原因 | 解决方案 |
| :--- | :--- | :--- | :--- |
| 1. | [任务1名称] | [你分析的问题原因] | **[类别]:** [你提出的解决方案] |
| 2. | [任务2名称] | [你分析的问题原因] | **[类别]:** [你提出的解决方案] |
| ... | ... | ... | ... |

你理解这些指示了吗？请开始分析。